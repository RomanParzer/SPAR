---
title: "[spar]{.pkg}: Sparse Projected Averaged Regression in [R]{.proglang}"
header-includes: #allows you to add in your own Latex packages
- \usepackage{float} #use the 'float' package
- \floatplacement{figure}{H} 
format:
    jss-pdf:
        keep-tex: true
    # jss-html: default
knitr:
  opts_chunk: 
    collapse: true
    comment: "#>" 
    prompt: true
    continue: true
author:
  - name: Roman Parzer
    affiliations:
      - name: TU Wien
        department: Computational Statistics (CSTAT), Institute of Statistics and Mathematical Methods in Economics
        address: Wiedner Hauptstraße 8-10
        city: Vienna
        country: Austria
        postal-code: 1040
    orcid: 0000-0003-0893-3190
    email: romanparzer1@gmail.com
  - name: Laura Vana Gür
    affiliations:
      - name: TU Wien
        department: Computational Statistics (CSTAT), Institute of Statistics and Mathematical Methods in Economics
        address: Wiedner Hauptstraße 8-10
        city: Vienna
        country: Austria
        postal-code: 1040
    orcid: 0000-0002-9613-7604
  - name: Peter Filzmoser
    affiliations:
      - name: TU Wien
        department: Computational Statistics (CSTAT), Institute of Statistics and Mathematical Methods in Economics
        address: Wiedner Hauptstraße 8-10
        city: Vienna
        country: Austria
        postal-code: 1040
    orcid: 0000-0002-8014-4682
    
abstract: |
  Package [spar]{.pkg} for [R]{.proglang} builds ensembles of predictive generalized linear models  with high-dimensional predictors. It employs an algorithm utilizing variable screening and random projection tools to efficiently handle the computational challenges associated with large sets of predictors.
  The package is designed with a strong focus on extensibility. Screening and random projection techniques are implemented as [S]{.proglang}3 classes with user-friendly constructor functions, enabling users to easily integrate and develop new procedures. This design enhances the package's adaptability and makes it a powerful tool for a variety of high-dimensional applications.

keywords: [random projection, variable screening, ensemble learning, R]
keywords-formatted: [random projection, variable screening, ensemble learning, "[R]{.proglang}"]

bibliography: SPAR.bib   
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.pos = "t!",
                      out.extra = "", continue = "+ ",
                      eval=TRUE)
```

## Introduction {#sec-intro}

The [spar]{.pkg} package for [R]{.proglang} [@RLanguage] offers functionality
for estimating generalized linear models (GLMs) in high-dimensional 
settings, where the number of predictors $p$ significantly exceeds the number 
of observations $n$ i.e., $p>n$ or even $p\gg n$. 
To address the challenges of
high dimensionality, the package implements an algorithm which integrates variable screening methods with
random projection techniques to effectively reduce the predictor space.

Random projection is a computationally-efficient method which linearly maps a 
set of points in high dimensions into a much lower-dimensional space. 
Several packages in [R]{.proglang} provide functionality for random
projections. For instance, package [RandPro]{.pkg}
[@RandProR; @SIDDHARTH2020100629] allows a Gaussian random matrix, a sparse matrix [@ACHLIOPTAS2003JL;@LiHastie2006VerySparseRP]
or a matrix generated using the equal probability distribution with the 
elements $\{-1,1\}$ to be applied to the predictor matrix before employing one of $k$ 
nearest neighbor, support vector machine or naive Bayes classifier on the 
projected features. Package [SPCAvRP]{.pkg} [@SPCAvRPR] implements sparse 
principal component analysis, based on the aggregation of eigenvector
information from "carefully-selected" axis-aligned random projections of the 
sample covariance matrix. Additionally, 
package [RPEnsembleR]{.pkg} [@RPEnsembleR] implements a similar idea when 
building the ensemble of classifiers: for each classifier in the ensemble,
a collection of 
(Gaussian, axis-aligned projections, or Haar) random projection matrices is 
generated, and the one that minimizes a risk measure 
for classification on a test set is selected.
For [Python]{.proglang} [@Python] the [sklearn.random\\_projection]{.pkg} 
module [@pedregosa2011scikit] implements two types of unstructured random
matrices, namely Gaussian random matrix and sparse random matrix.

Random projection can suffer from noise accumulation for very large $p$, 
as too many irrelevant predictors are being considered for prediction
purposes [@Dunson2020TargRandProj]. Therefore, screening out irrelevant 
variables before performing the random projection is advisable in order to 
tackle this issue. The screening can be performed in a probabilistic fashion, 
by randomly sampling covariates for inclusion in the model based on 
probabilities proportional to an importance measure (as opposed to random 
subspace sampling employed in, e.g.,
random forests). The [R]{.proglang} landscape for variable screening techniques 
is very rich. An overview of some notable packages on the Comprehensive [R]{.proglang} Archive Network (CRAN) includes the following packages. 
Package [SIS]{.pkg} [@SISR], which implements
the (iterative) sure independence screening procedure and its extensions, as detailed in @Fan2007SISforUHD, @Fan2010sisglms, @fan2010high. This package also provides functionality for estimating a penalized generalized linear model or a cox regression model for the variables selected by the screening procedure.
Package [VariableScreening]{.pkg} [@pkg:VariableScreening] offers screening methods for independent and identically distributed (iid) data, varying-coefficient models, and longitudinal data and includes techniques such as sure independent ranking and screening (SIRS), which ranks the predictors by their correlation with the rank-ordered response, or distance correlation sure independence screening (DC-SIS), a non-parametric extension of the correlation coefficient.
Package [MFSIS]{.pkg} [@pkg:MFSIS] provides a collection of model-free screening techniques including SIRS, DC-SIS, the fused Kolmogorov filter [@mai2015fusedkolmogorov] the projection correlation method using knock-off features [@liu2020knockoff], among others. Additional packages implement specific procedures but their review is beyond
the scope of the current paper.
<!-- Further packages are available which implement specific procedures: @pkg:tilting, @pkg:cdcsis, @pkg:QCSIS, @pkg:LqGm @pkg:fusionclust.  -->
<!-- Package [SMLE]{.pkg} [@pkg:SMLE] implements joint feature screening via sparse MLE [@SMLE2014] in high-dimensional linear, logistic, and Poisson models. Package [TSGSIS]{.pkg} [@pkg:TSGSIS] provides a high-dimensional grouped variable selection approach for detecting interactions that may not have marginal effects in high dimensional linear and logistic regression [@10.1093/bioinformatics/btx409]. -->

Although combining variable screening with random projection effectively
reduces the predictor set and computational costs, the variability introduced 
by random sampling -- both in projections and screening indices -- can be 
mitigated by averaging the results from multiple iterations [@Thanei2017RPforHDR].
To address these points, [spar]{.pkg} builds an ensemble of GLMs in the spirit 
of @Dunson2020TargRandProj and @parzer2024glms where, in each model of the 
ensemble, i) variables are first screened based on a screening coefficient,
ii) the selected variables are then projected to a lower dimensional space, 
iii) a GLM is estimated using the projected predictors.
Finally, additional sparsity in the coefficients of the original variables
can be introduced through a thresholding parameter, which together with the 
number of models in the
ensemble can be chosen using a validation set or via cross-validation.
The final coefficients are then obtained by averaging over the marginal
models in the ensemble. 
This algorithm
performs sparse projected averaged regression (SPAR) for both discrete and 
continuous data in the GLM framework in  a computationally 
efficient way. Different variants of the algorithm have been shown to perform 
well in terms of prediction power on a variety of datasets [see @Dunson2020TargRandProj]. In particular, @parzer2024glms show that when paired with a carefully constructed
data-driven random projection the algorithm performs superiorly in terms of 
predictions and variable ranking in settings exhibiting different degrees of sparsity in the coefficients.

A variety of screening coefficients are provided as well as several procedures for 
generating random
projection matrices. These procedures can be classified into 
data-agnostic and data-driven, where the former, unlike the latter, does not incorporate information from the data in the construction of the matrices. 
However, the package is designed with flexibility in mind, providing users 
with a versatile framework to extend the implemented screening and projection
techniques with their own custom procedures. This is facilitated by 
  leveraging [R]{.proglang}'s 
[S]{.proglang}3 classes, making the process convenient and user-friendly. 
Therefore, users can seamlessly integrate various techniques by either
writing their own procedures or leveraging the existing [R]{.proglang} packages.

The package provides methods such as `plot`, `predict`, `coef`,
`print`, which allow users to more easily interact with the model output and analyze the results. The GLM framework,
especially when combined with random projections which 
preserve information on the original coefficients 
[such as the one in @parzer2024glms], facilitates interpretability of the model output, allowing users to  understand variable effects.

While [spar]{.pkg} offers the first implementation of the 
described algorithm and, to the best of our knowledge, no 
other package offers the same functionality for GLMs, few other [R]{.proglang} packages
focus on building ensembles of *classifiers* where the  dimensionality of the predictors is reduced. 
Most notably, package [RPEnsemble]{.pkg}  [@RPEnsembleR]
implements the procedure in @cannings2017random where
"carefully-selected" random projections are used for projecting the predictors before they are employed in a classifier such as $k$-nearest neighbor, linear or quadratic discriminant analysis. 
On the other hand, package [RaSEn]{.pkg} [@pkg:RaSEn] implements the RaSE algorithm for ensemble classification and regression problems, where random subspaces are generated and the optimal one is chosen to train a weak learner on the basis of some criterion.


<!-- Regarding variable screening, users can seamlessly integrate various techniques by either writing their own procedures or leveraging the  -->

<!-- Therefore, no other package in [R]{.proglang} -->
<!-- provides the functionality of [spar]{.pkg} for GLMs.  -->


<!-- Various choices of base classifiers are implemented, for instance, linear discriminant analysis, quadratic discriminant analysis, $k$-nearest neighbor, logistic or linear regression, decision trees, random forest, support vector machines. The selected percentages of variables can be employed for variable screening. -->

<!-- Package [Ball]{.pkg} [@pkg:ball] provides functionality for variable screening using ball statistics, which is appropriate for shape, directional, compositional and symmetric positive definite matrix data. -->

<!-- Package [BayesS5]{.pkg} [@pkg:BayesS5] implements Bayesian variable selection using simplified shotgun stochastic search algorithm with screening [@shin2017scalablebayesianvariableselection] while package [bravo]{.pkg} [@pkg:bravo] implements the Bayesian iterative screening method proposed in [@wang2021bayesianiterativescreeningultrahigh]. -->

The rest of the paper is organized as follows: @sec-models provides the methodological details of the implemented algorithm. The package is described in @sec-software and @sec-extensibility exemplifies how a new screening coefficient and a new random projection can be integrated in the package. @sec-illustrations contains two examples of employing the package on real data sets. Finally, @sec-conclusion concludes.

## Methods {#sec-models}

The package implements a procedure for building an ensemble 
of GLMs where we employ screening and random projection 
to the predictor matrix pre-model estimation for the purpose of
dimensionality reduction.

Throughout the section we assume to observe 
high-dimensional data $\{(\boldsymbol{x}_i,y_i)\}_{i=1}^n$, 
where $\boldsymbol{x}_i\in\mathbb{R}^p$ is a predictor vector and $y_i\in\mathbb{R}$ is the response, with $p\gg n$. The predictor vectors are collected in the rows of the predictor matrix $X\in \mathbb R^{n\times p}$.

### Variable screening

In this section we provide an overview of possible approaches to performing variable screening in a high-dimensional setting. In high-dimensional modeling, the goal of variable screening is to reduce the predictor set by selecting a small subset of variables with a strong *utility* to the response variable. This initial selection enables more efficient downstream analyses by discarding less relevant predictors early in the modeling process, thus reducing computational costs and potential noise accumulation stemming from irrelevant variables [see e.g., @Dunson2020TargRandProj].

Classic approaches such as sure independence screening (SIS),
proposed by @Fan2007SISforUHD, use the vector of marginal empirical correlations 
$\hat\omega=(\omega_1,\ldots ,\omega_p)^\top\in\mathbb{R}^p,\omega_j=\text{Cor}(X_{j},y)$, 
where $y$ is the $(n\times 1)$ vector of responses and 
$X_{j}$ is the $j$-th column of the matrix of predictors,
to screen predictors in a linear regression setting
by selecting the variable set $\mathcal{A}_\gamma = \{j\in [p]:|w_j|>\gamma\}$ depending on a threshold $\gamma>0$, 
where $[p]=\{1,\dots,p\}$. Under certain technical conditions,  this screening coefficient has the *sure screening property*
$\Prob(\mathcal{A} \subset \mathcal{A}_{\gamma_n})\to 1 \text{ for } n\to \infty$,  where $\mathcal{A}=\{j\in[p]:\beta_j\neq 0\}$ is the set of truly active variables.
Extensions to SIS include modifications for GLMs [@Fan2010sisglms], where screening
is performed based on the log-likelihood $\ell(.)$ or the slope coefficient of the GLM containing only $X_j$ as a predictor: $\hat\omega_j=: \text{argmin}_{\beta_j\in\mathbb{R}}\text{min}_{{\beta_0}\in\mathbb{R}}\sum_{i=1}^n -\ell(\beta_j,\beta_0;y_i,x_{ij})$, where $x_{ij}$ is the $j$-th entry of the vector $x_i$.

However, both mentioned approaches face limitations related to 
the required technical conditions which can rule out practically possible
scenarios where an important variable is marginally uncorrelated to the response due to their multicollinearity. To tackle these issues,
@fan2009ultrahigh propose to 
use an iterative procedure where SIS is applied subsequently on the residuals of the model estimated in a previous step.
Additionally, in a linear regression setting,  @Wang2015HOLP
propose employing the ridge estimator when the penalty term converges to zero while @cho2012high propose using the tilted correlation, i.e., the correlation of a tilted version of $X_j$ with $y$ where the effect of other variables is reduced. For discrete outcomes, joint feature screening [@SMLE2014] has been proposed. 

In order to tackle potential model misspecification, a rich stream of literature focuses on developing semi- or non-parametric alternatives to SIS. For linear regression, approaches include using the ranked correlation [@zhu2011model], (conditional) distance correlation [@li2012feature;@wang2015conditional] or quantile correlation [@ma2016robust].
For GLMs, @fan2011nonparametric extend @Fan2010sisglms by fitting a generalized additive model with B-splines. Further extensions for discrete (or categorical) outcomes include the fused Kolmogorov filter [@mai2013kolmogorov], the mean conditional variance, i.e., the expectation in $X_j$ of the variance in the response of the conditional cumulative
distribution function $\Prob(X\leq x|Y)$ [@cui2015model].
@ke2023sufficient propose a model free method where the contribution of each individual predictor is quantified marginally and conditionally in the presence of the control variables as well as the other candidates by reproducing-kernel-based $R^2$ and partial 
$R^2$ statistics.


Package [spar]{.pkg} allows the integration of such (advanced) screening techniques using a flexible framework, which in turn enables users to apply various screening methods tailored to their data characteristics in the algorithm generating the ensemble. This flexibility allows users to evaluate different strategies, ensuring that the most effective approach is chosen for the specific application at hand. Moreover, it incorporates probabilistic screening strategies, which can be
particularly useful in ensembles, as they enhance the diversity of predictors across ensemble models. Instead of relying on a fixed threshold or number of predictors to be screened, predictors are sampled with probabilities proportional to their screening score [see @Dunson2020TargRandProj;@parzer2024glms].


### Random projection tools {#sec-rps}

Package [spar]{.pkg} has been designed to allow the incorporation of various random projection techniques, enabling users to tailor the procedure to their specific data needs. Below, we provide background information on random projection techniques and an overview of possible choices for building such random projection matrices.

The random projection method relies on the Johnson-Lindenstrauss (JL) lemma [@JohnsonLindenstrauss1984], which asserts that for each set of
points in $p$-dimensional Euclidean space collected in the rows of 
$X\in \mathbb{R}^{n\times p}$ there exists a linear map 
$\Phi\in \mathbb{R}^{m \times p}$ such that all pairwise distances are approximately preserved within a factor of $(1\pm\epsilon)$ for $m\geq m_0=\mathcal O(\epsilon^{-2}\log(n))$.
<!-- and it also gives a lower bound on the goal dimension $m$ in order to preserve the distances between all pairs of points within a factor $1\pm \varepsilon$: -->
<!-- $m>\frac{24\log n}{3\varepsilon^2-2\varepsilon^3}$ for any $0 <\varepsilon< 1$.  -->
Computationally, an attractive feature of the method for high-dimensional settings is that the bound does not depend on $p$.

The goal is to choose a random map $\Phi$ that satisfies the JL lemma with high probability given that it fulfills certain technical conditions. The literature focuses on constructing such matrices either by sampling them from some "appropriate" distribution, 
by inducing sparsity in the matrix and/or by employing specific fast constructs which lead to efficient matrix-vector multiplications.
It turns out that the conditions are generally satisfied by
nearly all sub-Gaussian distributions [@matouvsek2008variants]. 
A common choice is the standard normal
distribution $\Phi_{ij} \overset{iid}{\sim} N(0,1)$ [@FRANKL1988JLSphere] or a sparser version where
$\Phi_{ij}\overset{iid}{\sim} N(0,1/\sqrt{\psi})$ 
with probability $\psi$
and $0$ otherwise [@matouvsek2008variants].
Another computationally simpler option  is the Rademacher distribution where
$\Phi_{ij} =  \pm 1/\sqrt{\psi}$ with probability $\psi/2$ and zero otherwise for  $\quad 0<\psi\leq 1$,
where @ACHLIOPTAS2003JL shows results for $\psi=1$ and $\psi=1/3$ while @LiHastie2006VerySparseRP recommend using $\psi=1/\sqrt{p}$ to obtain very sparse matrices.

Further approaches include using the Haar measure to generate random orthogonal matrices [@cannings2017random] or 
a non-sub-Gaussian distribution like the standard Cauchy, 
proposed by @LiHastie2006VerySparseRP for preserving approximate $\ell_1$ distances in settings where the data is high-dimensional, non-sparse, and heavy-tailed.
<!-- TODO: citation -->
Structured matrices, which allow for more efficient multiplication, have also been proposed
[see e.g., @ailon2009fast;@Clarkson2013LowRankApprox].
<!-- propose the fast Johnson- Lindenstrauss transform (FJLT), where the random projection matrix is given by $\Phi=PHD$ with $P$ random and sparse, $P_{ij} \sim N (0, 1/q)$ with probability $1/q$ and $0$ otherwise, $H$ the normalized Hadamard (orthogonal) matrix $H_{ij} = p^{-1/2}(-1)^{\langle i-1,j-1\rangle}$, where $\langle i, j\rangle$ is the dot-product of the $m$-bit vectors $i$, $j$ expressed in binary, and $D = \text{diag}(\pm 1)$ is a diagonal matrix with random elements $D_{ii}$. -->
<!-- TODO: find a refernce for this, check if it holds -->
<!-- An orthonormalization is usually applied  $(\Phi\Phi^\top)^{-1/2}\Phi$. -->
<!-- Orthonormalization can constitute a computational bottleneck -->
<!-- for the random projection method, however, in high-dimensions it can be omitted.  -->

The conventional random projections mentioned above are 
data-agnostic. However, recent work has proposed incorporating information  from the data either to select the "best" random projection or to directly inform the random projection procedure.
For example, @cannings2017random
build an ensemble classifier where 
the random projection matrix is chosen by 
selecting the one that minimizes the test error of the 
classification problem among a set of data-agnostic random projections. 

On the other hand,  @parzer2024glms propose
to use a random projection matrix for GLMs which directly incorporates 
information about the relationship between the predictors and 
the response in the projection matrix, rather than a projection matrix which satisfies the JL lemma. @parzer2024sparse also provide in the linear regression 
a theoretical bound on the expected gain in prediction error in using a
projection which incorporates information
about the true $\beta$ coefficients compared to a conventional random projection.
Motivated by this result, they propose to construct a projection matrix using 
the sparse embedding matrix of @Clarkson2013LowRankApprox, where the random 
diagonal elements are replaced in practice by a ridge coefficient with a minimal 
$\lambda$ penalty. This method has the advantage of approximately capturing the true beta in the span of the random projection, 
i.e., it ensures that the true regression coefficients can be
recovered 
approximately after the projection. 
<!-- which is in general not possible with conventional random projections  -->
<!-- [@Thanei2017RPforHDR].  -->

Moreover, another data-driven approach to random projection for  regression has been proposed by  @ryder2019asymmetric,
who propose a data-informed random projection using an asymmetric transformation of the predictor matrix without using information 
of the response.


<!-- @Clarkson2013LowRankApproxShort propose a sparse embedding matrix ${\Phi=BD}$, where $B\in\{0,1\}^{m \times p}$ is random binary matrix and $D$ is a $p\times p$ diagonal matrix with $(D_{ii}+1)/2\sim \text{Unif}\{0,1\}$, and prove that the dimension $m$ is bounded by -->
<!-- a polynomial in $r\varepsilon^{-1}$ for $0 <\varepsilon< 1$ and $r$ being the rank of $X$. While this is generally larger than that of FJLT, the sparse embedding matrix requires less time to compute $\Phi X$ compared to other subspace embeddings. -->




<!-- see more info at https://www.cs.waikato.ac.nz/~bobd/ECML_Tutorial/ECML_handouts.pdf. -->

<!-- See also https://web.math.princeton.edu/~amits/publications/LeanWalsh_published.pdf. -->

<!-- https://arxiv.org/pdf/1710.03163.pdf -->

<!-- https://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf -->

<!-- https://people.math.ethz.ch/~nicolai/mv/notes6.pdf -->

<!-- https://web.math.princeton.edu/~amits/publications/LeanWalsh_published.pdf -->

<!-- https://pastel.hal.science/tel-01481912/document -->


### Generalized linear models 

After we perform in each marginal model an
initial screening step followed
by a projection step, 
we assume that the reduced and projected set of 
predictors $\boldsymbol{z}_i$ together with the response arises from a GLM with the response having conditional density from a (reproductive) exponential dispersion family of the form 
\begin{align*}\label{eqn:y_density}
  f(y_i|\theta_i,\phi) = \exp\Bigl\{\frac{y_i\theta_i- b(\theta_i)}{a(\phi)} + c(y_i,\phi)\Bigr\},
  \quad
    g(\E[y_i|\boldsymbol{z}_i]) = \gamma_0 + \boldsymbol{z}_i^\top\boldsymbol{\gamma}=:\eta_i,
\end{align*}
where $\theta_i$ is the natural parameter,  $a(.)>0$ and $c(.)$ are specific real-valued functions determining different families, $\phi$ is a dispersion parameter, and 
$b(.)$ is the log-partition function normalizing the density to integrate to one. If $\phi$ is known, we obtain densities in the natural exponential family for our responses. 
The responses are related to the $m$-dimensional reduced and projected predictors through the conditional mean, i.e., 
the conditional mean of $y_i$ given ${\boldsymbol{z}}_i$
depends on a linear combination of the predictors through a (invertible) link function $g(.)$, where $\gamma_0\in\mathbb{R}$ is the intercept and $\boldsymbol{\gamma}\in\mathbb{R}^m$ is a vector of regression coefficients for the $m$ projected predictors.

Given that $m$, the goal dimension of the projection need not necessarily be small in comparison to $n$ 
(we recommend using a dimension of at most $n/2$),
we observe that adding a small $L_2$ penalty in the marginal models, especially for the binomial family, can make estimation more stable as it alleviates problems
related to separation. The marginal models we estimate therefore
involve minimizing the following function:
$$
 \text{argmin}_{{\gamma}\in\mathbb{R}^m}\min_{\gamma_0\in\mathbb{R}}  \sum_{i=1}^n -\ell(\gamma_0, \gamma;y_i,\boldsymbol{z}_i) + \frac{\varepsilon}{2}\sum_{j=1}^m{\gamma}_j^2, \, \varepsilon > 0.
$$
We will employ for this purpose the 
function `glmnet()` of package [glmnet]{.pkg} 
[@glmnet2023] in the estimation of the marginal models.

### SPAR algorithm {#sec-algo}

We present the general algorithm for sparse projected averaged regression (SPAR)
implemented in package [spar]{.pkg}. 

1. Dog
    1. German Shepherd
    2. Belgian Shepherd
        1. Malinois
        2. Groenendael
        3. Tervuren
2. Cat
    1. Siberian
    2. Siamese


  1.  Choose family with corresponding log-likelihood $\ell(.)$ and link.
  
  2.   Standardize the $(n\times p)$ matrix of predictors $X$ for all
    families and the vector of responses $y$ for the  Gaussian  family by subtracting the sample column mean and dividing by the sample standard deviation. 
  
  3.   Calculate screening coefficients $\hat\omega$.
  
  4.   For $k=1,\dots,M$ models:

      a. If $p>2n$, screen $2n$ predictors based on the screening coefficient 
    $\hat\omega$, which yields for model $k$ the screening index set
    $I_k=\{j_1^k,\dots,j_{2n}^k\}\subset[p]$; if probabilistic screening should 
    be employed draw the predictors sequentially without replacement using an 
    initial vector of probabilities $p_j\propto |\hat\omega_j|$. Otherwise, 
    select the $2n$ variables with the highest $|\hat\omega_j|$. If $p < 2n$, 
    perform no screening and $I_k=\{1,\dots,p\}$.
      b. project screened variables to a random dimension 
    $m_k\sim \text{Unif}\{\log(p),\dots,n/2\}$ using \textbf{projection matrix} 
    $\Phi_k$ to obtain $Z_k=X_{\cdot I_k}\Phi_k^\top \in \mathbb{R}^{n\times m_k}$, 
    where $X_{\cdot I_k}$ contains the columns in $X$ having a column index in 
    $I_k$.
      c. fit a ($L_2$ penalized) \textbf{GLM} of $y$ on $Z_k$ to obtain estimated 
    coefficients $\widehat\gamma^k\in\mathbb{R}^{m_k}$ and 
    $\hat \beta_{I_k}^k=\Phi_k^\top\widehat\gamma^k$, $\hat \beta_{\bar I_k}^k=0$.

5.   For a given threshold $\nu>0$, set all $\hat\beta_j^k$ with $|\hat\beta_j^k|<\nu$ to $0$ for all $j,k$.

6.   Choose $M$ and $\nu$ via a validation set or cross-validation by repeating steps 1 to 4 and employing a
loss function $K(M, \nu)$ on the test set 
\begin{align*}
         (M_{\text{best}},\nu_{\text{best}}) = \text{argmin}_{M,\nu}K(M,\nu).
       \end{align*}

7.   Combine models of the ensembles via the coefficients using **simple average** 
$\hat \beta = \sum_{k=1}^M\hat \beta^k / M$.

8. Output the estimated coefficients and predictions for the chosen $M$ and $\nu$.

## Software {#sec-software}

The package can be installed from [GitHub]{.proglang} 
```{r eval=FALSE}
devtools::install_github("RomanParzer/SPAR")
```
and loaded by
```{r}
library("spar")
```
In this section we rely for illustration purposes on the example data set 
from the package which contains $n=200$ observations of a continuous response 
`y` and $p=2000$ predictors `x` which can be used as a training data set and 
$n=100$ observations to be used as a test set.
```{r}
data("example_data", package = "spar")
str(example_data)
```
This data set has been simulated from a linear regression model
with $\sigma^2=83$, an intercept $\mu=1$ and $\beta$ coefficients
with 100 non-zero entries, where the non-zero entries are uniformly 
sampled from $\{-3,-2,-1,1,2,3\}$.


### Main functions and their arguments

The two main functions for fitting the SPAR algorithm are:
```
spar(x, y, family = gaussian("identity"), model = NULL, 
  rp = NULL, screencoef = NULL,
  xval = NULL, yval = NULL, nnu = 20, nus = NULL, nummods = c(20),
  measure = c("deviance", "mse", "mae", "class", "1-auc"),
  inds = NULL, RPMs = NULL, ...)
```
which implements the algorithm in @sec-algo without cross-validation and 
returns an object of class [spar]{.class}, 
and
```
spar.cv(x, y, family = gaussian("identity"), model = NULL, 
  rp = NULL, screencoef = NULL,
  nfolds = 10, nnu = 20, nus = NULL, nummods = c(20),
  measure = c("deviance", "mse", "mae", "class", "1-auc"), ...)
```
which implements the cross-validated procedure and returns an object of 
class [spar.cv]{.class}.

The common arguments of these functions are:

-   `x`  an $n \times p$ numeric matrix of predictor variables,

-   `y` numeric response vector of length $n$,

-   `family` object from [stats::family]{.fct}; defaults to `gaussian()`; 

-   `model` an object of class [sparmodel]{.class} which specifies the model employed for each element of the ensemble.

-   `rp` an object of class [randomprojection]{.class}, defaults to 
`rp_cw(data = TRUE)`;

-   `screencoef` an object of class [screencoef]{.class},
defaults to `screen_glmnet()`;

-    `nnu` is the number of threshold values $\nu$ which should be considered for thresholding; defaults to 20;

-   `nus` is an optional vector of $\nu$ values to be considered for thresholding. If it is not provided, is defaults to a grid of `nnu` values. This grid is generated by including zero and `nnu`$-1$ quantiles of the absolute values of the estimated coefficients from the marginal models,
chosen to be equally spaced  on the probability scale .


-   `nummods` is the number of models to be considered in the ensemble;
    defaults to 20. If a vector is provided, all combinations of `nus` and 
     `nummods` are considered when choosing the optimal $\nu_\text{best}$ and $M_\text{best}$.

-   `measure` specifies the measure $K(\nu, M)$ based on which the thresholding value $\nu_\text{opt}$ and the number of models `M` should be chosen on the validation set (for `spar()`) or in each of the folds (in `spar.cv()`). 
The default value for `measure` is `"deviance"`, which is available for all families. 
Other options are mean squared error `"mse"` or mean absolute error `"mae"`
(between responses and predicted conditional means, for all families), 
`"class"` (misclassification error) and `"1-auc"` 
(one minus area under the ROC curve) both just for binomial family.

Furthermore, `spar()` has the specific arguments:

-  `xval` and  `yval` which are used as validation sets for choosing $\nu_\text{best}$ and $M_\text{best}$. If not provided, `x` and  `y` will be employed.

- `inds` is an optional list of length `max(nummods)` containing column index-vectors corresponding to variables that should be kept after screening for each marginal model; dimensions need to fit those of the dimensions of the provided matrices in `RPM`.

-   `RPMs` is an optional list of length `max(nummods)` which contains  projection matrices to be used in each marginal model. 

Function `spar.cv()` has the specific argument `nfolds` which is the number of folds to be used for cross-validation. It relies on `spar()`
as a workhorse, which is called for each fold. The random projections
for each model are held fixed throughout the cross-validation
to reduce the computational burden. This is possible by calling `spar()`
in each fold with a predefined `inds` and `RPMs` argument,
which are generated by first calling `spar()` on the whole 
dataset, before starting the cross-validation procedure. 
However, it is possible to specify whether the data associated with the random projection (relevant for data-driven random projections) should be updated in each fold iteration with the corresponding training data. This is achieved by modifying elements of the [randomprojection]{.class} object, which we will exemplify in @sec-extensibility.



### Screening coefficients

The objects for creating screening coefficients are implemented as \proglang{S}3 classes [screencoef]{.class}. These objects are created by
several implemented `screen_*` functions, which take as arguments
`...` (to be saved as attributes) and  `control` (a list of controls to be used  in the main function for computing the 
screening coefficient).

Consider as an example function `screen_marglik` which
implements a screening procedure based on  the coefficients of univariate GLMs:
```{r}
screen_marglik
```

Arguments related to the screening procedure can be passed through `...`, and will be saved as attributes of the [screencoef]{.class} object.
More specifically, the following attributes are relevant for function `spar()`:

  * `nscreen` integer giving the number of variables to be retained after screening; defaults to $2n$.
  
  * `split_data_prop`, double between 0 and 1 which indicates the proportion of the data that should be used for computing the screening coefficient. The remaining data will be used for estimating the marginal models in the SPAR algorithm; defaults to `NULL`. In this case the whole data will be used for estimating the 
  screening coefficient and the marginal models.
  
  * `type` character -- either `"prob"` (indicating that probabilistic screening
  should be employed)  or `"fixed"` (indicating that a fixed set of `nscreen`
  variables should be employed across the ensemble); defaults to `type = "prob"`.
  
The `control` argument, on the other hand, is a list
containing extra parameters to be passed to the 
main function computing the screening coefficients. 


The following screening coefficients are implemented in [spar]{.pkg}:

* `screen_marglik()` - computes the screening coefficients by the coefficient of $x_j$ for $j =1,\dots,p$  in a univariate GLM using the `stats::glm()` function. 
 $$
 \hat\omega_j=:\text{argmin}_{\beta_j\in \mathbb{R}}\text{min}_{{\beta_0}\in\mathbb{R}}\sum_{i=1}^n -\ell(\beta_0,\beta_j;y_i,x_{ij})
 $$
 It allows to pass a list of controls through the `control` argument to `stats::glm` such as weights, family, offsets.

* `screen_cor()` -- computes the screening coefficients by the correlation between $y$ and $x_j$ using the function `stats::cor()`. It allows to pass a list of controls through the `control` argument to `stats::cor`.

* `screen_glmnet()` -- computes by default the ridge coefficient 
where the penalty $\lambda$ is very small [see @parzer2024glms for clarification]. 
$$
\hat\omega=: text{argmin}_{\beta\in \mathbb{R}^p}\text{min}_{{\beta_0}\in\mathbb{R}}\sum_{i=1}^n -\ell(\beta;y_i,x_i) + \frac{\varepsilon}{2}\sum_{j=1}^p{\beta}_j^2, \, \varepsilon > 0
$$
The function 
relies on `glmnet::glmnet()` and, while it assumes by 
default $\alpha = 0$ and a small penalty, it allows to pass a list of 
controls through the `control` argument to `glmnet::glmnet()` such 
as `alpha = 1`. This screening coefficient is used as a default if `screencoef = NULL` in function call of
`spar()` or `spar.cv()`.


All implemented `screen_*` functions return an object of class [screencoef]{.class}
which in turn is a list with three elements: 
  
  * a character `name`, 
  
  * `generate_fun()` -- an [R]{.proglang} function for generating the screening coefficient. This
  function should have as following arguments:  `x` -- the matrix of standardized predictors --  and `y` -- the vector of (standardized in the Gaussian case) responses, 
  and the argument `object`, which is a [screencoef]{.class} object itself. 
  It returns a vector of screening coefficients of length $p$.
  
  * `control`, which is the control list passed by the user in `screen_*`. These controls are 
  arguments which are needed in `generate_fun()` in order to generate the desired 
  screening coefficients.
  


For illustration purposes, consider the object created by calling `screen_marglik()`:
```{r}
obj <- screen_marglik()
```
A user-friendly `print` of the [screencoef]{.class} is provided:
```{r}
obj
```
The structure of the object is the following:
```{r}
unclass(obj)
```
Function `generate_fun()` defines the generation of the screening coefficient. Note that it considers the controls in `object$control` when calling
the `stats::glm()` function (unless it is provided, the `family` argument in `stats::glm()` will be set to the "global" family of the SPAR algorithm which is assigned
inside the `spar()` function an attribute for the [screencoef]{.class} object). 


For convenience, a constructor function `constructor_screencoef()`
is provided, which can be used to create new `screen_*` functions.  An example is presented in @sec-extensscrcoef.


### Random projections

Similar to the screening procedure, 
the objects for creating random projections are
implemented as \proglang{S}3
classes [randomprojection]{.class} and are created by functions
`rp_*(..., control = list())`, 
which take `...` and a list of controls `control` as arguments. 

Arguments related to the random projection
can be passed through `...`, which will
then be saved as attributes of the [randomprojection]{.class} object.
More specifically, the following attributes are relevant in
the SPAR algorithm:

  * `mslow`: integer giving the minimum dimension to which the predictors should
  be projected; defaults to $\log(p)$.
  
  * `msup`: integer giving the maximum dimension to which the predictors should
  be projected; defaults to $n/2$.
  
  * `data`: boolean indicating whether the random projection is data-driven.
  
Note that for random projection matrices which satisfy the JL lemma, `mslow`
can be determined by employing existing results which give 
a lower bound on the goal dimension in order to preserve the distances between 
all pairs of points within a factor $(1 \pm \epsilon)$.
For example, @ACHLIOPTAS2003JL show $m_0 = \log n(4 + 2\tau)/(\epsilon^2/2 − \epsilon^3/3)$ for probability
$1 − n^{-\tau}$.


The following random projections are implemented in [spar]{.pkg}:

* `rp_gaussian()` -- random projection object where the generated matrix will have iid entries from a normal distribution (defaults to standard normal entries)

* `rp_sparse()` -- random projection object where the generated matrix will be the one in [@ACHLIOPTAS2003JL] with `psi = 1` by default.

* `rp_cw()` -- sparse embedding random projection in [@Clarkson2013LowRankApprox]  for `rp_cw(data = FALSE)`. Defaults to `rp_cw(data=TRUE)`, which replaces the random elements on the diagonal by the ridge coefficients with a small penalty, as introduced in @parzer2024glms.


The `rp_*` functions return an object of class [randomprojection]{.class}
which  is a list with three elements: 
  
  * `name`, 
  
  * `generate_fun()` function for generating the random projection matrix. This
    function should have arguments \code{rp}, which is itself a [randomprojection]{.class}
    object, \code{m}, the target dimension and a vector of indices
    \code{included_vector} which indicates the column index of the original variables
    in the \code{x} matrix to be projected using the random projection. 
    This is needed due to the fact that screening can be employed pre-projection. It can return a matrix or a sparse matrix of class 
    [dgCMatrix]{.class} of the [Matrix]{.pkg} with `m` rows and 
    `length(included_vector)` columns.

  * `update_data_rp()` optional function used for data-driven random projections, which updates the [randomprojection]{.class} object with data information which is relevant for the random projection. The updating happens only once, before the start of the SPAR algorithm, where appropriate attributes are added to the [randomprojection]{.class} object. All relevant quantities
  are to be used in the `generate_fun()` function.
  This
function should have arguments \code{rp}, which is a [randomprojection]{.class} object to be updated, `x` -- the matrix of standardized predictors --  and `y` -- the vector of (standardized in the Gaussian case) responses. Returns a [randomprojection]{.class} object.
  
  * `update_rpm_w_data()` optional function for updating the random projection matrices provided in the argument `RPMs` of functions `spar` and `spar.cv` with data-dependent parameters. While `update_data_rp` is employed only once at the start of the algorithm, `update_rpm_w_data` specifies how to modify each random projection provided in `RPMs`. 
This is particularly relevant for the cross-validation procedure, which employs the random projection matrices 
generated by calling the `spar()` function on the whole dataset before starting the cross-validation exercise.For example, in our implementation of the data-driven `rp_cw()`, we only update `RPMs` by adjusting with the vector of 
screening coefficients computed on the current training data in each fold, but do not modify the random elements in each fold, to reduce the computational burden.
Defaults  to `NULL`. If not provided, the values of the provided `RPMs` do not change. 
 
  * `control`, which is the control list in `rp_*`. These controls are arguments needed in `generate_fun()` in order to generate the desired random projection.
  

For illustration purposes, consider the implemented function
`rp_gaussian()`, which generates a random projection with entries drawn from the normal distribution.
The `print` method returns key information about the random projection procedure.
```{r}
obj <- rp_gaussian()
obj
```
We turn to looking at the structure of the object:
```{r}
unclass(obj)
```
The `generate_fun()` function returns a matrix with  `m` rows and `length(included_vector)` columns.
Note that `included_vector` gives the indices of the 
variables which have been selected by the screening 
procedure. In this case, where the random projection does 
not use any data information, we are only interested in the 
length of this vector. 

The functions `update_data_fun()` and `update_rpm_w_data()` are `NULL`
as this conventional 
random projection is data-agnostic. 

### Marginal models

The package provides a class [sparmodel]{.class}
for the marginal model to be fitted for
each element of the ensemble. The framework currently 
assumes that the linear predictor is a linear combination of 
the projected variables. 

Similar to the objects for random projection and screening
coefficients, the functions which create these objects 
have arguments `...` (to be saved as attributes) and  `control` (to be used 
in the main function for building the model).

The two functions implemented are `spar_glmnet()`, which allows regularized GLMs
as marginal models using function `glmnet::glmnet()` (where the default is to
estimate a ridge regression with the small penalty value), 
and `spar_glm()` which estimates unregularized GLMs using `stats::glm.fit()`.

An object of class [sparmodel]{.class} is a list with elements: 
  
  * `name`, 
  * `model_fun()` -- a function which takes `y` (the vector of standardized 
  responses), `z` (the matrix of reduced predictors) and a further argument 
  which is the object of class [sparmodel]{.class} itself. 
  * `update_model()` -- an optional function which can add further attributes to 
  the [sparmodel]{.class} object which is called at the beginning of the SPAR 
  algorithm. In the case of `spar_glmnet()` this function manipulates the 
  [family]{.class} object in a way which is convenient for `glmnet::glmnet()`.
  \footnote{In the case of families Gaussian, binomial and Poisson with 
  canonical link, the family object is replaced by a string containing the 
  name of the family. This leads to [glmnet]{.pkg} using the faster specialized 
  algorithms rather than the general algorithm implemented for all 
  [family]{.class} objects.}
  
The default is to use `spar_glm()` for Gaussian family with identity link 
and `spar_glmnet()` for the other families.

### Methods 


Methods `print`, `plot`, `coef`, `predict` are available for both [spar]{.class}
and [spar.cv]{.class} classes.

#### print
The `print` method returns information on $\nu_\text{best}$
$M_\text{best}$, the number of active predictors
(i.e., predictors which have at least a nonzero coefficient across the marginal models)
and a five-point summary of the non-zero coefficients.
```{r}
spar_res <- spar(example_data$x, example_data$y,
                 xval = example_data$xtest,
                 yval = example_data$ytest,
                 nummods = c(5,10,15,20,25,30))
spar_cv <- spar.cv(example_data$x, example_data$y,
                   nummods = c(5,10,15,20,25,30))
```


```{r}
spar_res
```

```{r}
spar_cv
```


#### coef
Method `coef` takes as inputs a `spar` or `spar.cv` object, together with further arguments: 

* `nummod` --	number of models used to compute the averaged coefficients; value of `nummod` with minimal  `measure` is used if not provided.

* `nu` -- threshold level used to compute the averaged coefficients; value with minimal  `measure` is used if not provided.

```{r}
str(coef(spar_res))
```

It returns a list with the intercept, vector of `beta` coefficients and the `nummod` and `nu` employed in the calculation.

Additionally for [spar.cv]{.class}, the `coef` method 
also has argument `opt_par` which is one of 
`c("1se","best")` and chooses whether to select the best pair of `nus` and `nummods` according to cross-validation 
`measure`, or the solution yielding sparsest vector of coefficients
within one standard deviation
of that optimal cross-validation 
`measure`. This argument is ignored when `nummod` and `nu` are given.

#### predict
Functionality for computing predictions is provided through the method `predict` which takes a `spar` or `spar.cv` object, 
together with

* `xnew` --	matrix of new predictor variables; must have same number of columns as `x`.

* `type` --	the type of required predictions; either on `"response"` level (default) or on `"link"` level

* `avg_type` --	type of averaging used across the marginal models; either on `"link"` (default) or on `"response"` level

* `nummod` --	number of models used to compute the averaged coefficients; 
value of `nummod` with minimal  `measure` is used if not provided.

* `nu` -- threshold level used to compute the averaged coefficients; value with minimal  `measure` is used if not provided.

* `coef` --	optional vector of coefficients to be used directly in the prediction.

Additionally, for class [spar.cv]{.class}, argument `opt_par` is available and used in the computation of the 
coefficients to be used for prediction (see above description of  method `coef`). 


#### plot

Plotting functionality is provided through the `plot` method, 
which takes a `spar` or `spar.cv` object, 
together with further arguments:

* `plot_type` -- one of:

  * `"Val_Measure"` plots the (cross-)validation `measure` for either a grid of `nu` values for a fixed number of models `nummod` or viceversa.

  * `"Val_numAct"` plots the number of active variables for either a grid of `nu` values for a fixed number of models `nummod` or viceversa.
  
  * `"res-vs-fitted"` produces a residuals-vs-fitted plot. The residuals are computed as $y- \widehat y$, where $\widehat y$ is the prediction computed on response level.
   
  * `"coefs"`  produces a plot of the value of the standardized coefficients for each predictor in each marginal model (before thresholding).  For each predictor, the values of the coefficients are sorted from largest to smallest 
  across the marginal models and then represented in the plot.

* `plot_along` -- one of `c("nu","nummod")`; for 
`plot_type = "Val_Measure"` or `plot_type = "Val_numAct"` it indicates whether the values of the cross-validation measure or number of active variables, respectively, should be shown for a grid of $\nu$ values while keeping the number of models `nummod` fixed or viceversa. This argument is ignored when `plot_type = "res-vs-fitted"` or `plot_type = "coefs"`.

* `nummod` -- fixed value for number of models when `plot_along = "nu"` for `plot_type = "Val_Measure"` or `"Val_numAct"`;  if `plot_type = "res-vs-fitted"`, it is used in the `predict` method, as described above.

* `nu` -- fixed value for  $\nu$ when `plot_along = "nummod"` 
for `plot_type = "Val_Measure"` or `"Val_numAct"`; if `plot_type = "res-vs-fitted"`, it is used in the `predict` method, as described above.


* `xfit` -- if `plot_type = "res-vs-fitted"`, it is the matrix of
predictors used in computing the fitted values. This argument must be
provided for the plot of residuals and fitted values, as the [spar]{.class} or [spar.cv]{.class} objects do not store the original data.

* `yfit` -- if `plot_type = "res-vs-fitted"`, vector of
responses used in computing the residuals. This argument must be
provided for the plot of residuals and fitted values, as the [spar]{.class} or [spar.cv]{.class} objects do not store the original data.

* `prange` -- optional vector of length 2 in case `plot_type = "coefs"` which gives the limits of the predictors' plot range; defaults to `c(1, p)`.

*  `coef_order` --  optional index vector of length $p$ in case
`plot_type = "coefs"` to give the order of the predictors; defaults to `1 : p`.

For class [spar.cv]{.class} there is the extra argument
`opt_par = c("best", "1se")` which, for `plot_type = "res-vs-fitted"` indicates whether the predictions 
should be based on coefficients using the best $(\nu, M)$ combination or 
on the combination which delivers the sparsest 
$\beta$ having validation measure within one standard deviation from the minimum

The `plot` methods return objects of class "`ggplot`" [@ggplotR].

## Extensibility {#sec-extensibility}
 
###  Screening coefficients {#sec-extensscrcoef}

We exemplify how new screening coefficients implemented in package 
[VariableScreening]{.pkg} can easily be used in the framework of
[spar]{.pkg}. 

We start by defining the function for generating the screening coefficients
using the `screenIID()` function in [VariableScreening]{.pkg}.
```{r}
generate_scr_sirs <- function(y, x, object) {
    res_screen <- do.call(function(...) 
      VariableScreening::screenIID(x, y, ...), 
      object$control)
    coefs <- res_screen$measurement
    coefs
  }
```
Note that `screenIID()` also takes method as an argument. 
To allow for flexibility, we do not
fix the method in `generate_scr_sirs()` but rather allow the user to 
pass a method through the `control` argument in the `screen_*` function.
This function is created using the helper `constructor_screencoef()`:
```{r sirs_chunk}
screen_sirs <- constructor_screencoef(
    "screen_sirs", 
    generate_fun = generate_scr_sirs)
```

We now call the `spar()` function with the newly created screening procedure.
We consider the method SIRS of @zhu2011model, which ranks the predictors by their correlation with the rank-ordered response and we do not perform probabilistic variable
screening but employ the top $2n$ variables in each marginal model.
```{r}
set.seed(123)      
spar_example <- spar(example_data$x, example_data$y,
    screencoef = screen_sirs(type = "fixed",
      control=list(method = "SIRS")),
                   measure = "mse")
spar_example
```

### Random projections

We exemplify how new random projections can be implemented
in the framework of [spar]{.pkg}. 

We implement the random projection of @cannings2017random, 
who propose using the Haar measure for generating the random projections. 
They simulate matrices from the Haar measure by 
independently drawing each entry of a matrix $Q$ from a
standard normal distribution, and then to take the projection matrix to 
be the transpose of the matrix of left singular vectors in
the singular value decomposition of $Q$.
Moreover, they suggest using "good" random projections, in the sense that they deliver the best out-of-sample prediction. The
proposed approach employs $B_1$ models in an ensemble of classifiers and for each model $k$, $B_2$ data independent
random projections are generated and the one with the lowest 
error on a test set is the one chosen to project the variables
in model $k$.

We can implement such a random projection in [spar]{.pkg}
by the following building block: 
```{r }
update_data_cannings <- function(rp, x, y) {
  attr(rp, "data") <- list(x, y)
  rp
}
```
This is the function which adds data information to the random projection object. Here, the whole data can be added as information for the $M$ random projection (alternatively,
one could only pass sufficient statistics for computing the 
desired measures).

While the $B_2$ random projections are data-agnostic, 
the `generate_fun()` element of the random projection will 
need the data information in order to evaluate which method performs best in terms of an error measure.
We will, in the following, define the function for the generation
of the 
random projection matrix to be used in a  model $k$.

This helper simulates $m\times p$ matrices from the Haar measure:
```{r}
simulate_haar <- function(m, p) {
    R0 <- matrix(1/sqrt(p) * rnorm(p * m), nrow = p, ncol = m)
    RM <- qr.Q(qr(R0))[, seq_len(m)]
    RM <- Matrix::Matrix(t(RM), sparse = TRUE)  
}
```

The function that generates the random projection matrix for 
model $k$ uses 25% of the data as a test set for choosing the best among 
$B_2$ random projections in terms of minimizing misclassification error for 
the binomial family and MSE for all other families:
```{r }
generate_cannings <- function(rp, m, included_vector) {
    p <- length(included_vector)
    if (is.null(rp$control$B2)) rp$control$B2 <- 50
    x <- attr(rp, "data")$x[, included_vector]
    y <- attr(rp, "data")$y
  
    B2 <- rp$control$B2
    n <- nrow(x)
    id_test <- sample(n, size = n %/% 4)
    xtrain <- x[-id_test, ];  xtest <- x[id_test,]
    ytrain <- y[-id_test];  ytest <- y[id_test]
  
    if (is.null(rp$control$family)) rp$control$family <- attr(rp, "family")
  
    family <- rp$control$family
    control_glm <-
      rp$control[names(rp$control) %in% names(formals(glm.fit))]

    error_all <- lapply(seq_len(B2), FUN = function(s){
      RM <- simulate_haar(m, p)
      xrp <- tcrossprod(xtrain, RM)
      mod <- do.call(function(...) 
       glm.fit(x =  cbind(1, xrp), y = ytrain, ...), control_glm)
      eta_test <- (cbind(1, tcrossprod(xtest, RM)) %*% mod$coefficients)
      pred <- family$linkinv(as.vector(eta_test))
      out <-  ifelse(family$family == "binomial",
                     mean(((pred > 0.5) + 0) != ytest), 
                     mean((pred - ytest)^2))
      list(RM, out)
   })
   id_best <- which.min(sapply(error_all, "[[", 2))
   RM <- error_all[[id_best]][[1]]
   return(RM)
  }
```
In the cross-validation procedure, we do not generate new matrices for each step to keep computational costs low, so we do not specify a function `update_rpm_w_data()`.

Putting it all together, we get:
```{r }
rp_cannings <- constructor_randomprojection(
    "rp_cannings",
    generate_fun = generate_cannings,
    update_data_fun = update_data_cannings
  )
```

We can now estimate SPAR for a binomial model, where we transform the response to a binary variable. 
```{r }
ystar <- (example_data$y > 0) + 0
ystarval <- (example_data$ytest > 0) + 0
```

We use $100$ models (which is in line to recommendations for $B_1$ in @cannings2017random), and no screening procedure. 
If no screening is desired, `nscreen` can be set to `p`
in the `screen_*` function:
```{r echo=FALSE}
file <- "cannings_example.rda"
if (file.exists(file)) {
  load(file)
} else {
  set.seed(123)   
  spar_example_1 <- spar(
    x = example_data$x, y = ystar,
    xval = example_data$xtest, yval = ystarval,
    family = binomial(),
    nummods = 100, 
    screencoef = screen_marglik(nscreen = ncol(example_data$x)),
    rp = rp_cannings(control = list(B2 = 50)),
    measure = "class"
  )
  set.seed(123)   
  spar_example_2 <- spar(
    x = example_data$x, y = ystar,
    family = binomial(),
    screencoef = screen_marglik(nscreen = ncol(example_data$x)),
    rp = rp_cw(data = TRUE),
    nummods = 100, 
    xval = example_data$xtest, yval = ystarval,
        measure = "class"
  )
  save(spar_example_1, spar_example_2, 
       file = file)
}

```
```{r eval=FALSE}
set.seed(123)   
spar_example_1 <- spar(x = example_data$x, y = ystar,
    family = binomial(),
    screencoef = screen_marglik(nscreen = ncol(example_data$x)),
    rp = rp_cannings(control = list(B2 = 50)),
    nummods = 100, 
    xval = example_data$xtest, yval = ystarval,
    measure = "class"
  )
```
Using the data-driven `rp_cw()`:
```{r eval=FALSE}
set.seed(123)   
spar_example_2 <- spar(x = example_data$x, y = ystar,
    family = binomial(),
    screencoef = screen_marglik(nscreen = ncol(example_data$x)),
    rp = rp_cw(data = TRUE),
    nummods = 100, 
    xval = example_data$xtest, yval = ystarval,
    measure = "class"
  )
```
We can extract the measures on the validation set by:
```{r}
head(spar_example_1$val_res)
```
We can now compare the two approaches by looking at the minimum measure `Meas`  
achieved on the validation set:
```{r}
min_val_1 <- min(spar_example_1$val_res$Meas)
id_best_1 <- max(which(spar_example_1$val_res$Meas == min_val_1))
min_val_2 <- min(spar_example_2$val_res$Meas)
id_best_2 <- max(which(spar_example_2$val_res$Meas == min_val_2))
spar_example_1$val_res[id_best_1, ]
spar_example_2$val_res[id_best_2, ]
```
            
## Illustrations {#sec-illustrations}

### Face image data

We illustrate the functionality of [spar]{.pkg} on the Isomap data set 
containing $n = 698$
black and white face images of size $p = 64 \times 64 = 4096$ together
with the 
faces' horizontal looking direction angle as the response 
variable.\footnote{
The Isomap face data can be found online on https://web.archive.org/web/20160913051505/http://isomap.
stanford.edu/datasets.html.}
```{r eval=FALSE}
url1 <- "https://web.archive.org/web/20150922051706/"
url2 <- "http://isomap.stanford.edu/face_data.mat.Z"
download.file(paste0(url1, url2),
              file.path("face_data.mat.Z"))
system('uncompress face_data.mat.Z')
```
```{r ,echo=FALSE}
if (!file.exists("face_data.mat")) {
  url <- "https://web.archive.org/web/20150922051706/http://isomap.stanford.edu/face_data.mat.Z"
  library("R.matlab")
  download.file(url, file.path("face_data.mat.Z"))
  system(sprintf('uncompress %s', paste0("face_data.mat.Z")))
}
```

The `.mat` file format can be read using [R.matlab]{.pkg} [@pkg:rmatlab]:
```{r message=FALSE}
library("R.matlab")
facedata <- readMat(file.path("face_data.mat"))
x <- t(facedata$images)
y <- facedata$poses[1,]
```
We can visualize one observation in this data set in
Figure \ref{fig:facesplot1} (code for reproducing the figure is provided 
in the supplementary materials).
```{r, include=FALSE, echo=FALSE,fig.width=8, fig.height=8,out.width="50%", fig.pos="t",fig.fullwidth=FALSE}
library(ggplot2)
i <- 179
p <- ggplot(data.frame(X = rep(1:64,each=64),
                  Y = rep(64:1,64),
                  Z = facedata$images[,i]),
       aes(X, Y, fill = Z)) +
  geom_tile() +
  theme_void() +
  ggtitle(paste0("y = ", round(facedata$poses[1, i],1))) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5))
ggsave(filename = "Figures/faces_obs_415.pdf", p)
```
\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{Figures/faces_obs_415.pdf}
\caption{Image corresponding to one observation in the \emph{Isomap faces} data set. \label{fig:facesplot1}}
\end{figure}

This data set has the issue of many columns being almost constant, which can make
estimation unstable. Given that `spar()`
and `spar.cv()` ignore constant columns, we can alleviate this issue by setting
all columns which have a low standard deviation to zero.
```{r}
x[, apply(x, 2, sd) < 0.01] <- 0
```

We split the data into training vs test sample
```{r}
set.seed(123)
ntot <- length(y); ntest <- ntot * 0.25
testind <- sample(ntot, ntest, replace = FALSE)
xtrain <- as.matrix(x[-testind, ]); ytrain <- y[-testind]
xtest <- as.matrix(x[testind, ]); ytest <- y[testind]
```

We now estimate on the training data the SPAR algorithm with cross-validation. 
We employ the data-driven random projection proposed in @parzer2024sparse
with screening based on the ridge coefficients. To ensure convergence 
of the [glmnet]{.pkg} algorithm, we set the `lambda.min.ratio` parameter to 
$0.001$. Moreover, each marginal model will a ridge linear regression,
with a small penalty (the minimal penalty produced by `glmnet::glmnet()`).
```{r echo=FALSE}
file <- "faces_spar_result.rda"
if (!file.exists(file)) {
  set.seed(123)
  control_glmnet <- list(lambda.min.ratio = 0.001)
  library("spar")
  spar_faces <- spar.cv(
    xtrain, ytrain,
    model = spar_glmnet(control = control_glmnet),
    screencoef = screen_glmnet(control = control_glmnet),
    rp = rp_cw(data = TRUE, 
               control = control_glmnet),
    nummods = c(5, 10, 20, 50),
    measure = "mse")
  save(spar_faces, file = file)
} else {
  load(file)
}
```
```{r eval=FALSE}
library("spar")
set.seed(123)
control_glmnet <- list(lambda.min.ratio = 0.001)
spar_faces <- spar.cv(
  xtrain, ytrain,
  model = spar_glmnet(control = control_glmnet)
  screencoef = screen_glmnet(control = control_glmnet),
  rp = rp_cw(data = TRUE, control = control_glmnet),
  nummods = c(5, 10, 20, 50),
  measure = "mse")
```
```{r}
spar_faces
```
The `plot` method for [spar.cv]{.class} objects displays by default the 
measure employed in the cross-validation (in this case MSE) 
for a grid of $\nu$
values, where the number of models is fixed to the value found to perform 
best in cross-validation exercise (see Figure \ref{fig:facesplot_valmeasure}). 
```{r, eval=F}
plot(spar_faces)
```
```{r echo=TRUE, include=FALSE}
p <- plot(spar_faces, digits = 4L)
ggsave(filename = "Figures/faces_plot_valmeasure.pdf", p,
       width = 10, height = 5)
```
\begin{figure}[t!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/faces_plot_valmeasure.pdf}
\caption{Plot of mean squared error over a grid of threshold values $\nu$ for fixed number of optimal models $M=20$ for the \emph{Isomap faces} data set.
The red points correspond to the threshold which achieves the lowest
cross-validation measure and the one with the largest cross-validation 
measure within one standard deviation away from minimum. Confidence bands represent one standard deviation in the measures across the number of folds. \label{fig:facesplot_valmeasure}}
\end{figure}


We observe that no thresholding delivers the lowest MSE but that using thresholds
between $7e-4$ and $1.1e-3$ does not cause a large increase in MSE. The 
1-standard-error rule would suggest picking $\nu=0.00508$.

The coefficients of the different variables (in this example pixels) obtained by
averaging over the coefficients the marginal models (for optimal $\lambda$ and 
number of models) are given by:
```{r}
face_coef <- coef(spar_faces, opt_par = "best")
str(face_coef)
```
For a sparser solution we can compute the coefficients using 
`opt_par = "1se"` which leads to more sparsity and a lower number of models.
```{r}
face_coef_1se <- coef(spar_faces, opt_par = "1se")
str(face_coef_1se)
```
The standardized coefficients from each of `max(nummods)` models 
(before averaging and before thresholding) can be plotted by setting 
`plot_type = "coefs"` (see resulting plot in Figure\~\ref{fig:faces_coefs}). 
```{r , eval=FALSE, fig.width=15, fig.height=8,out.width="80%", fig.pos="center", fig.cap=""}
plot(spar_faces, plot_type = "coefs")
```
```{r echo=TRUE, include=FALSE}
p <- plot(spar_faces, plot_type = "coefs")
ggsave(filename = "Figures/faces_plot_coefs.pdf", p,
       width = 8, height = 5)
```
\begin{figure}[t!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/faces_plot_coefs.pdf}
\caption{Coefficient plot for all variables and all $M=50$ models in the SPAR ensemble for the \emph{Isomap faces} data set. The coefficients are standardized, before thresholding.
\label{fig:faces_coefs}}
\end{figure}

We observe that pixels close to each other have more correlation than pixels further apart.

The `predict()` function can be applied to the [spar.cv]{.class} object.
We will employ the sparser solution chosen by the `opt_par = "1se"` rule:
```{r }
ynew <- predict(spar_faces, xnew = xtest, coef = face_coef_1se)
```
In the high-dimensional setting it is interesting to look at the relative mean 
square prediction error which compares the MSE to the MSE of a model containing only an intercept:
```{r }
rMSPEconst <- mean((ytest - mean(y))^2) 
mean((ynew-ytest)^2)/rMSPEconst
```
Additionally, for this data set, one can visualize the effect of each pixel 
$\hat\beta^\text{1se}_j x^\text{new}_{i,j}$ in predicting the face orientation in a given image e.g., the 11th one in the test set. The contribution of each pixel can be visualized in Figure \ref{fig:faces_predictions}.
```{r echo=FALSE, fig.width=8, fig.height=8,out.width="50%", fig.pos="center", fig.cap=""}
i <- 3
plot4 <- ggplot(data.frame(X = rep(1:64, each = 64),
                           Y = rep(64:1, 64),
                           effect = xtest[i,] * face_coef_1se$beta), 
                aes(X, Y, fill = effect)) +
  geom_tile() +
  theme_void() +
  scale_fill_gradient2() +
  ggtitle(bquote(hat(y) == .(round(ynew[i])))) +
  theme(plot.title = element_text(hjust = 0.5)) 
ggsave(filename = "Figures/faces_plot_predictions.pdf", plot4, 
       width = 10, height = 7)
```
\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{Figures/faces_plot_predictions.pdf}
\caption{The effect of each pixel $\hat\beta^\text{1se}_j x^\text{new}_{i,j}$ in predicting the face orientation in Figure \ref{fig:facesplot1}. \label{fig:faces_predictions}}
\end{figure}

### Darwin data set

The Darwin dataset [@CILIA2022darwin] contains a binary response for Alzheimer's disease (AD) together with extracted features from 25 handwriting tests (18 features per task) for 89 AD patients and 85 healthy people ($n=174$).\footnote{The data set can be downloaded from  https://archive.ics.uci.edu/dataset/732/darwin}
```{r eval=FALSE}
download.file("https://archive.ics.uci.edu/static/public/732/darwin.zip",
              "darwin.zip")
```
```{r ,echo=FALSE}
if (!file.exists("data.csv")) {
  download.file("https://archive.ics.uci.edu/static/public/732/darwin.zip",
                "darwin.zip")
}
```
```{r}
darwin_tmp <- read.csv(unzip("darwin.zip",  "data.csv"), 
                       stringsAsFactors = TRUE)
```
Before proceeding with the analysis, the data is screened for 
multivariate outliers using the DDC algorithm in package [cellWise]{.pkg}
[@rcellwise].
```{r }
darwin_orig <- list(
  x = darwin_tmp[, !(colnames(darwin_tmp) %in% c("ID", "class"))],
  y = as.numeric(darwin_tmp$class) - 1)
tmp <- cellWise::DDC(
  as.matrix(darwin_orig$x),
  list(returnBigXimp = TRUE, 
       tolProb = 0.999,
       silent = TRUE))
darwin <- list(x = tmp$Ximp, y = darwin_orig$y)
```
The structure of the data is:
```{r}
str(darwin)
```

We estimate the SPAR algorithm with the screening and random projection
introduced in @parzer2024glms for binomial family and logit link, 
using $1-$area under the ROC curve as the cross-validation measure,
```{r }
spar_darwin <- spar.cv(darwin$x, darwin$y,
                       family = binomial(logit),
                       nummods = c(5, 10, 20, 50),
                       measure = "1-auc")
```

We can look at the average number of active variables for
a grid of $\nu$  where the number of models is fixed to the value found to perform
best in cross-validation exercise by using the 
`plot` method for [spar.cv]{.class} (see Figure \ref{fig:darwin_activevars}). 
We observe again that no thresholding achieves the best measure and translates 
to almost all variables being active (some variables can be inactive at $\nu=0$ as they may never be screened).
The 1-standard-error rule would however indicate that more sparsity can be introduced without too much increase in the cross-validation measure.
```{r eval=FALSE, fig.width=10, fig.height=6, fig.pos="center", out.width="80%", fig.cap=""}
plot(spar_darwin, plot_type = "Val_numAct")
```
```{r echo=TRUE, include=FALSE}
p <- plot(spar_darwin, plot_type = "Val_numAct", digits=3L)
ggsave(filename = "Figures/darwin_plot_valnumAct.pdf", p,
       width = 8, height = 5)
```
\begin{figure}[t!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/darwin_plot_valnumAct.pdf}
\caption{Average number of active variables for the grid of thresholding values 
$\nu$ and $M=10$ models for the \emph{Darwin} data set. The red points correspond to the average number of active variables for the model with the lowest cross-validation measures and to the one chosen by the 1-standard-error rule. \label{fig:darwin_activevars}}
\end{figure}
The coefficients of the predictors across the maximum number of 
considered marginal models (in this case $M=50$) can be visualized with `plot`.
In the dataset, the predictors are ordered by task, where the first 18 covariates represent different features measured for the first task. 
Given that there is clear grouping in the variables in this example, we can reorder the coefficients for plotting by grouping them by feature, rather than task.
This allows to assess how the different features (e.g., time it takes to 
complete a certain task) relate to the likelihood of having AD and how stable the
sign and magnitude of the coefficient is across the models in the ensemble.
We can achieve this by using reordering argument `coef_order` in method `plot` with `plot_type = "coefs"` (see Figure \ref{fig:darwin_coefs} which can be reproduced with code in the
supplementary materials).
```{r echo=FALSE, fig.width=10, fig.height=6, fig.pos="center",out.width="50%", fig.cap=""}
ntasks <- 25
nfeat <- 18
reorder_ind <- c(outer(
  (seq_len(ntasks) - 1) * nfeat,
  seq_len(nfeat), "+"))
feat_names <- sapply(colnames(darwin$x)[seq_len(nfeat)],
                     function(name) substr(name, 1, nchar(name) - 1))

p <- plot(spar_darwin,"coefs",coef_order = reorder_ind) + 
  geom_vline(xintercept = 0.5 + seq_len(ntasks - 1) * ntasks, 
             alpha = 0.2, linetype = 2) +
  annotate("text",x = (seq_len(nfeat) - 1) * ntasks + 12,
           y = 45,label=feat_names, angle = 90,
           size = 3)
ggsave(filename = "Figures/darwin_plot_coefs.pdf", p,
       width = 8, height = 5)
```
\begin{figure}[t!]
\centering
\includegraphics[width=0.8\textwidth]{Figures/darwin_plot_coefs.pdf}
\caption{Coefficient plot for all variables and all considered $M=50$ models in the SPAR ensemble
\emph{Darwin} data set. The coefficients are standardized, before thresholding. \label{fig:darwin_coefs}}
\end{figure}
In general we observe that the different features measures across different tasks have the same impact on the probability of AD (observable by the blocks of blue or red lines).

## Conclusion {#sec-conclusion}

Package [spar]{.pkg} can be employed for modeling data in a high-dimensional setting, where the number of predictors is much higher than the number of 
observations. The package provides an implementation an algorithm for  sparse projected and
average regression (SPAR) proposed in @parzer2024glms
which combines variable screening and random projection in an ensemble of
GLMs. 
The package provides flexible classes for i) specifying the 
coefficient based on which screening should be performed (both in a classical fashion, where the predictors with the highest screening coefficient 
are selected for subsequent or in a probabilistic fashion, where variables are
sampled for inclusion with probabilities proportional to their 
screening coefficient), ii) generating the random projection 
to be employed in each marginal model. Screening coefficients based on 
marginal correlation between the predictors and the response, marginal coefficients from a GLM or ridge coefficients are provided in the package.
Moreover, several random projections are implemented:
the Gaussian and sparse matrices which are data-agnostic and satisfy the JL 
lemma and the data-driven projection proposed in @parzer2024sparse for linear
regression and extended to GLMs in @parzer2024glms. This data-driven random 
projection has the advantage of allowing the true 
regression coefficients to be approximately
recovered after the projection, which is in general not possible with 
conventional random projections [@Thanei2017RPforHDR].
Methodologically, the SPAR algorithm particularly when paired with the
data-driven random projection in @parzer2024glms has been demonstrated
to perform effectively across different degrees of sparsity of the coefficient
vector and to offer
competitive predictions and variable ranking in both sparse and dense settings.

The flexibility and adaptability of the [spar]{.pkg} package make it an 
attractive choice for practitioners and researchers. It encourages exploration 
of new methods for variable screening and random projections or the 
combination of existing approaches to tailor solutions to specific data 
requirements.



## Computational details {.unnumbered .unlisted}

The results in this paper were obtained using [R]{.proglang} 
`r paste(R.Version()[6:7], collapse = ".")`.

[R]{.proglang} itself and all packages used are available from CRAN
at \url{https://CRAN.R-project.org/}.

## Acknowledgments {.unnumbered .unlisted}

Roman Parzer and Laura Vana-Gür acknowledge funding from the Austrian Science
Fund (FWF) for the project "High-dimensional statistical learning: New methods
to advance economic and sustainability policies" (ZK 35), jointly carried out 
by WU Vienna University of Economics and Business, Paris Lodron University
Salzburg, TU Wien, and the Austrian Institute of Economic Research (WIFO).

## References {.unnumbered .unlisted}

